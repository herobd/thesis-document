\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{icdarComp2017}
\citation{icdarComp2017}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{ix}{toclistings.1}}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Retsinas2015}
\citation{Retsinas2015}
\citation{sudholt2017}
\citation{sudholt2017}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{xv}{toclistings.2}}
\citation{icfhrComp2016,wigington2017,icdarComp2017}
\citation{icdarComp2017}
\citation{icfhrComp2016}
\citation{wigington2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{manmatha1996}
\citation{manmatha1996}
\citation{liang2012}
\citation{liang2012}
\citation{Clawson2014}
\citation{Clawson2014}
\citation{Zagoris2015}
\citation{Zagoris2015}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Examples of word spotting for `pay' and `payment'.\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:explain_spotting}{{1.1}{2}{Examples of word spotting for `pay' and `payment'.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Examples of subword spotting for the character trigram `pay' (left, red) and bigram `pa' (right, yellow).\relax }}{2}{figure.caption.2}}
\newlabel{fig:explain_sub_spotting}{{1.2}{2}{Examples of subword spotting for the character trigram `pay' (left, red) and bigram `pa' (right, yellow).\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Why Subword Spotting?}{3}{section.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Cropped examples of the characters ``e'' and ``i'' (excluding dots), on the left and right respectively, from a single author. Without context the characters are practically indistinguishable.\relax }}{4}{figure.caption.3}}
\newlabel{fig:ei}{{1.3}{4}{Cropped examples of the characters ``e'' and ``i'' (excluding dots), on the left and right respectively, from a single author. Without context the characters are practically indistinguishable.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces An example of a word having ``pa'' and ``men'' spotted in it. A regular expression representing this, \texttt  {pa..?men..?}, yields only a few matches from our lexicon, including the correct one: ``pavement'', ``pavements'', ``\textbf  {payment}'', and ``payments''.\relax }}{5}{figure.caption.4}}
\newlabel{fig:subtransexample}{{1.4}{5}{An example of a word having ``pa'' and ``men'' spotted in it. A regular expression representing this, \texttt {pa..?men..?}, yields only a few matches from our lexicon, including the correct one: ``pavement'', ``pavements'', ``\textbf {payment}'', and ``payments''.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Main Contributions}{5}{section.1.2}}
\citation{Rodr覺guez2008}
\citation{Rodr覺guez2008}
\citation{Shekhar2012}
\citation{Shekhar2012}
\citation{Rothacker2013}
\citation{Rothacker2013}
\citation{Rodr覺guez2008}
\citation{Rodr覺guez2008}
\citation{Rath2003}
\citation{Rath2003}
\citation{Marti2001}
\citation{Marti2001}
\citation{Bunke2004}
\citation{Bunke2004}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{relatedwork}{{2}{7}{Related Work}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Word Spotting}{7}{section.2.1}}
\newlabel{relatedwork_wordspotting}{{2.1}{7}{Word Spotting}{section.2.1}{}}
\citation{Aldavert2015}
\citation{Aldavert2015}
\citation{Almazan2014}
\citation{Almazan2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of how vertical slice window features are extracted. Typically most features are extracted on a binarized image (a). Deskewing the image (b) plays an important role as the vertical slices are very sensitive to skew. Many typical features extracted (c) are pixel counts; in this example we show count features dependent on baselines (blue).\relax }}{8}{figure.caption.5}}
\newlabel{fig:vertslice}{{2.1}{8}{Example of how vertical slice window features are extracted. Typically most features are extracted on a binarized image (a). Deskewing the image (b) plays an important role as the vertical slices are very sensitive to skew. Many typical features extracted (c) are pixel counts; in this example we show count features dependent on baselines (blue).\relax }{figure.caption.5}{}}
\citation{sudholt2016,sudholt2017}
\citation{sudholt2016}
\citation{sudholt2017}
\citation{Almazan2014}
\citation{Almazan2014}
\citation{krishnan2016,retsinasTrans2017}
\citation{krishnan2016}
\citation{retsinasTrans2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{wilkinson2017}
\citation{wilkinson2017}
\citation{Rothacker2013}
\citation{Rothacker2013}
\citation{Fischer2012}
\citation{Fischer2012}
\citation{Almazan2012}
\citation{Almazan2012}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a three-level PHOC vector for the word ``face''. The final vector is all levels appended together. Note that partial values are given when characters are split over bins.\relax }}{9}{figure.caption.6}}
\newlabel{fig:phoc}{{2.2}{9}{Example of a three-level PHOC vector for the word ``face''. The final vector is all levels appended together. Note that partial values are given when characters are split over bins.\relax }{figure.caption.6}{}}
\citation{CTC}
\citation{CTC}
\citation{icdarComp2017}
\citation{icdarComp2017}
\citation{wigington2017,puigcerver2017}
\citation{puigcerver2017}
\citation{wigington2017}
\citation{icdarComp2017}
\citation{icdarComp2017}
\citation{icdarComp2017}
\citation{icdarComp2017}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Automatic Handwriting Recognition}{10}{section.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Computer Assisted Transcription}{10}{section.2.3}}
\citation{Serrano2010}
\citation{Serrano2010}
\citation{Toselli2007}
\citation{Toselli2007}
\citation{Toselli2008}
\citation{Toselli2008}
\citation{Toselli2009}
\citation{Toselli2009}
\citation{Toselli2010}
\citation{Toselli2010}
\citation{Serrano2014}
\citation{Serrano2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of lines extracted from the dataset of the ICDAR HTR competition \cite  {icdarComp2017}.\relax }}{11}{figure.caption.7}}
\newlabel{fig:germanlines}{{2.3}{11}{Example of lines extracted from the dataset of the ICDAR HTR competition \cite {icdarComp2017}.\relax }{figure.caption.7}{}}
\citation{Clawson2014}
\citation{Clawson2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces A screenshot of a demo of Toselli et al's multimodal CAT system. The red line is drawn by the user to indicate the need to insert a word into the automatically obtained transcription.\relax }}{12}{figure.caption.8}}
\newlabel{fig:Toselli_multimodalCAT}{{2.4}{12}{A screenshot of a demo of Toselli et al's multimodal CAT system. The red line is drawn by the user to indicate the need to insert a word into the automatically obtained transcription.\relax }{figure.caption.8}{}}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Neudecker2010}
\citation{Neudecker2010}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Clawson's CAT system for tabular documents.\relax }}{13}{figure.caption.9}}
\newlabel{fig:ii}{{2.5}{13}{Clawson's CAT system for tabular documents.\relax }{figure.caption.9}{}}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Retsinas2015}
\citation{Retsinas2015}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Clawson2014}
\citation{Clawson2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces A screen-shot of a the CAT system of Zagoris et al.\nobreakspace  {}\cite  {Zagoris2015}. The green text indicates hand labeling, the blue text indicates automatic labeling. You can see to the right of the current word (``must'') the current ranked list of spottings (blue boxes).\relax }}{14}{figure.caption.10}}
\newlabel{fig:zagoris}{{2.6}{14}{A screen-shot of a the CAT system of Zagoris et al.~\cite {Zagoris2015}. The green text indicates hand labeling, the blue text indicates automatic labeling. You can see to the right of the current word (``must'') the current ranked list of spottings (blue boxes).\relax }{figure.caption.10}{}}
\citation{Retsinas2015}
\citation{Retsinas2015}
\citation{Retsinas2015}
\citation{Retsinas2015}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces A screen-shot of a character session for ``?'' from Neudecker and Tzadok's CAT system \cite  {Neudecker2010}, taken directly from their report \cite  {Neudecker2010}. Notice how easy it is for a user to simply click on the erroneous classifications.\relax }}{15}{figure.caption.11}}
\newlabel{fig:carpet}{{2.7}{15}{A screen-shot of a character session for ``?'' from Neudecker and Tzadok's CAT system \cite {Neudecker2010}, taken directly from their report \cite {Neudecker2010}. Notice how easy it is for a user to simply click on the erroneous classifications.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Examples of a good cluster (`c') and an incoherent cluster (multiple character classes) taken from \cite  {Retsinas2015}.\relax }}{15}{figure.caption.12}}
\newlabel{fig:retsinas_ex}{{2.8}{15}{Examples of a good cluster (`c') and an incoherent cluster (multiple character classes) taken from \cite {Retsinas2015}.\relax }{figure.caption.12}{}}
\citation{IAM}
\citation{IAM}
\citation{bentham}
\citation{bentham}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Datasets}{17}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{datasets}{{3}{17}{Datasets}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}IAM Dataset}{17}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Bentham Dataset}{17}{section.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Examples of lines from the IAM dataset.\relax }}{18}{figure.caption.13}}
\newlabel{fig:IAMExamples}{{3.1}{18}{Examples of lines from the IAM dataset.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Census Names Dataset}{18}{section.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Excerpts from the Bentham dataset.\relax }}{19}{figure.caption.14}}
\newlabel{fig:BenthamExamples}{{3.2}{19}{Excerpts from the Bentham dataset.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Character Annotation}{20}{section.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Process for extracting names from US 1930 census forms for Census Names data set. We begin with registered forms (a). Then we average the images together (b). The average image is used to mark form boundaries manually (c). The lines are registered to specific census image (d). At each cell a peojection profile is computed around the cell boundaries (dark blue) (e). The cell boundaries are snapped to the histogram peaks (f). Word boundaries were manually annotated for each cell (g).\relax }}{21}{figure.caption.15}}
\newlabel{fig:makenames}{{3.3}{21}{Process for extracting names from US 1930 census forms for Census Names data set. We begin with registered forms (a). Then we average the images together (b). The average image is used to mark form boundaries manually (c). The lines are registered to specific census image (d). At each cell a peojection profile is computed around the cell boundaries (dark blue) (e). The cell boundaries are snapped to the histogram peaks (f). Word boundaries were manually annotated for each cell (g).\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Excerpts from the Census Names dataset.\relax }}{22}{figure.caption.16}}
\newlabel{fig:NamesExamples}{{3.4}{22}{Excerpts from the Census Names dataset.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Example of hand annotated character segmentation.\relax }}{22}{figure.caption.17}}
\newlabel{fig:charseg}{{3.5}{22}{Example of hand annotated character segmentation.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Lexicon}{23}{section.3.5}}
\citation{sudholt2016,sudholt2017}
\citation{sudholt2016}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{Almazan2014}
\citation{Almazan2014}
\citation{sudholt2017}
\citation{sudholt2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Subword Spotting}{25}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{subwordspotting}{{4}{25}{Subword Spotting}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Implementation}{25}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Architecture}{25}{subsection.4.1.1}}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{caffe}
\citation{caffe}
\citation{SPP}
\citation{SPP}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{adam}
\citation{adam}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Network architecture for embedding images as PHOC vectors. The numbers beneath each layer represent the number of channels. As the network uses temporal pyramid pooling before the fully connected layers, it can accept images of any size. Our archetivture differs from \cite  {sudholt2017} only in the number of channels of the last convolutional layer.\relax }}{26}{figure.caption.18}}
\newlabel{fig:network}{{4.1}{26}{Network architecture for embedding images as PHOC vectors. The numbers beneath each layer represent the number of channels. As the network uses temporal pyramid pooling before the fully connected layers, it can accept images of any size. Our archetivture differs from \cite {sudholt2017} only in the number of channels of the last convolutional layer.\relax }{figure.caption.18}{}}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Training}{27}{subsection.4.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Determining Window Widths}{27}{subsection.4.1.3}}
\newlabel{detirminewindowsize}{{4.1.3}{27}{Determining Window Widths}{subsection.4.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Running}{27}{subsection.4.1.4}}
\citation{sudholt2017}
\citation{sudholt2016}
\citation{sudholt2016}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{sudholt2016}
\citation{sudholt2016}
\citation{sudholt2016,sudholt2017}
\citation{sudholt2016}
\citation{sudholt2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Combining QbE Results}{28}{subsection.4.1.5}}
\newlabel{combine}{{4.1.5}{28}{Combining QbE Results}{subsection.4.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Analysis of Subword Spotting}{28}{section.4.2}}
\citation{sudholt2016}
\citation{sudholt2016}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces MAP for full word spotting results, reported for both query-by-string (QbS) and query-by-example (QbE). Results on Census Names uses network with SPP depth of 2 instead of 3. Using 3 yields QbS:0.525 and QbE:0.511.\relax }}{29}{table.caption.19}}
\newlabel{tab:wordspottingresults}{{4.1}{29}{MAP for full word spotting results, reported for both query-by-string (QbS) and query-by-example (QbE). Results on Census Names uses network with SPP depth of 2 instead of 3. Using 3 yields QbS:0.525 and QbE:0.511.\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Full Word Spotting}{29}{subsection.4.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Subword Spotting}{29}{subsection.4.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces MAP for subword spotting results on the Bentham and Census Names datasets, reported for query-by-string (QbS) and, query-by-example (QbE).\relax }}{30}{table.caption.20}}
\newlabel{tab:subwordspotting}{{4.2}{30}{MAP for subword spotting results on the Bentham and Census Names datasets, reported for query-by-string (QbS) and, query-by-example (QbE).\relax }{table.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Qualitative results for QbS subword spotting on the Bentham Dataset. Spottings show represent the top result for the various n-gram queries. We selected some of the better n-grams (`n', `pr', `sed') and worse n-grams (`z', `et', `tte') by MAP. Red boxes indicate incorrect spottings. \relax }}{31}{figure.caption.21}}
\newlabel{fig:qualSpot}{{4.2}{31}{Qualitative results for QbS subword spotting on the Bentham Dataset. Spottings show represent the top result for the various n-gram queries. We selected some of the better n-grams (`n', `pr', `sed') and worse n-grams (`z', `et', `tte') by MAP. Red boxes indicate incorrect spottings. \relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Qualitative results for QbS subword spotting on the Census Names Dataset. Spottings show represent the top result for the various n-gram queries. We selected some of the better n-grams (`m', `il', `hic') and worse n-grams (`y', `ss', `wer') by MAP. Red boxes indicate incorrect spottings. \relax }}{32}{figure.caption.22}}
\newlabel{fig:qualSpotNames}{{4.3}{32}{Qualitative results for QbS subword spotting on the Census Names Dataset. Spottings show represent the top result for the various n-gram queries. We selected some of the better n-grams (`m', `il', `hic') and worse n-grams (`y', `ss', `wer') by MAP. Red boxes indicate incorrect spottings. \relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces This shows the QbS MAP for 18 n-grams on the Bentham dataset for varying sliding window sizes. \relax }}{33}{figure.caption.23}}
\newlabel{fig:windowsizes}{{4.4}{33}{This shows the QbS MAP for 18 n-grams on the Bentham dataset for varying sliding window sizes. \relax }{figure.caption.23}{}}
\newlabel{fig:benthamUniSpot}{{4.5a}{34}{Unigrams\relax }{figure.caption.24}{}}
\newlabel{sub@fig:benthamUniSpot}{{a}{34}{Unigrams\relax }{figure.caption.24}{}}
\newlabel{fig:benthamBiSpot}{{4.5b}{34}{Bigrams\relax }{figure.caption.24}{}}
\newlabel{sub@fig:benthamBiSpot}{{b}{34}{Bigrams\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Results for QbS subword spotting on the Bentham dataset. N-grams are arrange in descending order of frequency in test set. Trigrams are not displayed for space reasons.\relax }}{34}{figure.caption.24}}
\newlabel{fig:benthamsub}{{4.5}{34}{Results for QbS subword spotting on the Bentham dataset. N-grams are arrange in descending order of frequency in test set. Trigrams are not displayed for space reasons.\relax }{figure.caption.24}{}}
\newlabel{fig:namesUniSpot}{{4.6a}{35}{Unigrams\relax }{figure.caption.25}{}}
\newlabel{sub@fig:namesUniSpot}{{a}{35}{Unigrams\relax }{figure.caption.25}{}}
\newlabel{fig:namesBiSpot}{{4.6b}{35}{Bigrams\relax }{figure.caption.25}{}}
\newlabel{sub@fig:namesBiSpot}{{b}{35}{Bigrams\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Results for QbS subword spotting on the Census Names dataset. N-grams are arrange in descending order of frequency in test set. Trigrams are not displayed for space reasons.\relax }}{35}{figure.caption.25}}
\newlabel{fig:namessub}{{4.6}{35}{Results for QbS subword spotting on the Census Names dataset. N-grams are arrange in descending order of frequency in test set. Trigrams are not displayed for space reasons.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces MAP for QbS subword spotting results for trigrams where we only use queries which have an occurrence count above a threshol1d (in the testing sets). MAP increases, demonstrating the least frequent n-grams are more difficult. Only trigrams are shown as the effect is more dramatic in these cases. A opposite trend is not observed for uni- or bigrams. \relax }}{36}{figure.caption.26}}
\newlabel{fig:remove}{{4.7}{36}{MAP for QbS subword spotting results for trigrams where we only use queries which have an occurrence count above a threshol1d (in the testing sets). MAP increases, demonstrating the least frequent n-grams are more difficult. Only trigrams are shown as the effect is more dramatic in these cases. A opposite trend is not observed for uni- or bigrams. \relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Respotting Subwords}{36}{subsection.4.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Unigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{37}{figure.caption.27}}
\newlabel{fig:unigram_respot}{{4.8}{37}{Unigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Bigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{38}{figure.caption.28}}
\newlabel{fig:bigram_respot}{{4.9}{38}{Bigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Trigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{38}{figure.caption.29}}
\newlabel{fig:trigram_respot}{{4.10}{38}{Trigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Applications of Subword Spotting}{39}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{applications}{{5}{39}{Applications of Subword Spotting}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Manual Transcription Assistant}{39}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Prefix/Suffix Spotting}{40}{section.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Transcription assistance using subword spotting. (a) The user selects an unknown character (``G'', red box) to search the documents. (b) The results of a QbE search are displayed, strength of highlight relative to spotting score. (c) A ranked list of matches is shown (best match at top). The user selects another instance to refine the results (blue arrow). (d) Combined QbE results. Exemplars are highlighted in blue. (e) Ranked combined results, a more common word, ``Grace'' (red arrow), has moved up to a more visible position.\relax }}{41}{figure.caption.30}}
\newlabel{fig:assist_demo}{{5.1}{41}{Transcription assistance using subword spotting. (a) The user selects an unknown character (``G'', red box) to search the documents. (b) The results of a QbE search are displayed, strength of highlight relative to spotting score. (c) A ranked list of matches is shown (best match at top). The user selects another instance to refine the results (blue arrow). (d) Combined QbE results. Exemplars are highlighted in blue. (e) Ranked combined results, a more common word, ``Grace'' (red arrow), has moved up to a more visible position.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Suffix spotting AP of individual suffixes for the IAM dataset. Arranged in descending order of frequency in test set.\relax }}{42}{figure.caption.31}}
\newlabel{fig:IAM_suffix}{{5.2}{42}{Suffix spotting AP of individual suffixes for the IAM dataset. Arranged in descending order of frequency in test set.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Suffix spotting AP of individual suffixes for the Census Names dataset. Arranged in descending order of frequency in test set.\relax }}{43}{figure.caption.32}}
\newlabel{fig:names_suffix}{{5.3}{43}{Suffix spotting AP of individual suffixes for the Census Names dataset. Arranged in descending order of frequency in test set.\relax }{figure.caption.32}{}}
\citation{krishnan2016}
\citation{krishnan2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Application of Subword Spotting to Transcription}{45}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{transcription}{{6}{45}{Application of Subword Spotting to Transcription}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Baseline: CAT Through PHOC Vectors}{45}{section.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces An overview of the CAT system which uses approved subword spottings. The arrows represent the flow of data. (a) Subword spotting is performed. (b) Spotting results are sorted an distributed as batches. (c) Users classify the spottings. (d) The spottings are aggregated into a regular expression. This yields a set of possible transcriptions in the lexicon. These are scored with word spotting on the word image. (e) The (reduced) list of possible transcriptions is sent to a user to selects the correct one.\relax }}{46}{figure.caption.33}}
\newlabel{fig:flow}{{6.1}{46}{An overview of the CAT system which uses approved subword spottings. The arrows represent the flow of data. (a) Subword spotting is performed. (b) Spotting results are sorted an distributed as batches. (c) Users classify the spottings. (d) The spottings are aggregated into a regular expression. This yields a set of possible transcriptions in the lexicon. These are scored with word spotting on the word image. (e) The (reduced) list of possible transcriptions is sent to a user to selects the correct one.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}CAT Through Approved Subword Spottings}{46}{section.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Subword Spotting}{47}{subsection.6.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}User Tasks and Interface}{47}{subsection.6.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2.1}Approval}{48}{subsubsection.6.2.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2.2}Transcription Selection}{48}{subsubsection.6.2.2.2}}
\newlabel{transtask}{{6.2.2.2}{48}{Transcription Selection}{subsubsection.6.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Spotting approval UI. Instance being classified is at the bottom of the interface (dark border). The desired label ``and'' is below it. The next label ``ing'' can be seen above it with its associated instances above it. \relax }}{49}{figure.caption.34}}
\newlabel{fig:spottingapproval}{{6.2}{49}{Spotting approval UI. Instance being classified is at the bottom of the interface (dark border). The desired label ``and'' is below it. The next label ``ing'' can be seen above it with its associated instances above it. \relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Word Completion / Regular Expression Generation}{50}{subsection.6.2.3}}
\newlabel{wordcompletion}{{6.2.3}{50}{Word Completion / Regular Expression Generation}{subsection.6.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Transcription selection UI. Both ``her'' and ``for'' have been spotted in the image. The user can remove spottings if they are incorrect (red `x's). The possible transcriptions are ordered according to their word spotting score; in many instances this puts the correct transcription at the top of the list. \relax }}{51}{figure.caption.35}}
\newlabel{fig:transcriptionselection}{{6.3}{51}{Transcription selection UI. Both ``her'' and ``for'' have been spotted in the image. The user can remove spottings if they are incorrect (red `x's). The possible transcriptions are ordered according to their word spotting score; in many instances this puts the correct transcription at the top of the list. \relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Receiving Transcription}{52}{subsection.6.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.5}Batch Distribution}{53}{subsection.6.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces A histogram of spotting instances for the bigram ``nd'' divided into true and false spottings. The true spottings forms a distribution distinct from the false. \relax }}{54}{figure.caption.36}}
\newlabel{fig:two_dist_ex}{{6.4}{54}{A histogram of spotting instances for the bigram ``nd'' divided into true and false spottings. The true spottings forms a distribution distinct from the false. \relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces A histogram of spotting instances for the unigram ``g'' divided into true and false spottings. The true spottings are almost inline with the false distribution making them indistinguishable. \relax }}{54}{figure.caption.37}}
\newlabel{fig:one_dist_ex}{{6.5}{54}{A histogram of spotting instances for the unigram ``g'' divided into true and false spottings. The true spottings are almost inline with the false distribution making them indistinguishable. \relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces A histogram of spotting instances for the bigram ``nd'' with a curve (red) representing the data as a single distribution. The green circle shows that the estimation greatly underestimates the tail indicating there is likely a strong true instance distribution present. \relax }}{55}{figure.caption.38}}
\newlabel{fig:tail_dist_ex}{{6.6}{55}{A histogram of spotting instances for the bigram ``nd'' with a curve (red) representing the data as a single distribution. The green circle shows that the estimation greatly underestimates the tail indicating there is likely a strong true instance distribution present. \relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.6}Receiving Spotting Approvals}{56}{subsection.6.2.6}}
\citation{Retsinas2015}
\citation{Retsinas2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.7}Alternate Mode: Don't Wait to Transcribe}{57}{subsection.6.2.7}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}CAT Through Approved Subword Spottings Using Clustering}{57}{section.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Clustering}{57}{subsection.6.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces The cluster spotting approval UI with a true cluster. One outlier has been identified by the user (darkened instance).\relax }}{58}{figure.caption.39}}
\newlabel{fig:clustergood}{{6.7}{58}{The cluster spotting approval UI with a true cluster. One outlier has been identified by the user (darkened instance).\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Spotting Approval Batch Distribution}{58}{subsection.6.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces The cluster spotting approval UI with a false cluster. No outliers are present.\relax }}{59}{figure.caption.40}}
\newlabel{fig:clusterbad}{{6.8}{59}{The cluster spotting approval UI with a false cluster. No outliers are present.\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Spotting Approval UI}{60}{subsection.6.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}CAT Through Unassisted Subword Spotting Using Dynamic Time-Warping Alignment}{60}{section.6.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces An example of a character probability vector for the word ``adultery''. The relative probability of each character (`a'-`z') at each horizontal position is represented both by the height and color of the graph. The discontinuities occuring at the begining and end of the word (e.g. see `x') occur due to the merging of unigram, bigram, and trigram scores.\relax }}{62}{figure.caption.41}}
\newlabel{fig:cpv}{{6.9}{62}{An example of a character probability vector for the word ``adultery''. The relative probability of each character (`a'-`z') at each horizontal position is represented both by the height and color of the graph. The discontinuities occuring at the begining and end of the word (e.g. see `x') occur due to the merging of unigram, bigram, and trigram scores.\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Evaluation of Transcription Strategies}{63}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Evaluation Method}{63}{section.7.1}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Results}{64}{section.7.2}}
\@writefile{lot}{\contentsline {table}{\numberline {7.1}{\ignorespaces Highlights in the results from simulations. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used. The PHOC vector method is the only method we tested able to transcribe words at a rate faster than manual transcription.\relax }}{65}{table.caption.42}}
\newlabel{tab:finalresults}{{7.1}{65}{Highlights in the results from simulations. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used. The PHOC vector method is the only method we tested able to transcribe words at a rate faster than manual transcription.\relax }{table.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}CAT Through PHOC Vectors Results}{65}{subsection.7.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}CAT Through Approved Subword Spottings Results}{65}{subsection.7.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {7.2}{\ignorespaces Results from simulations of CATTSS using user approval on subword spotting results. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used.\relax }}{66}{table.caption.43}}
\newlabel{tab:appresults}{{7.2}{66}{Results from simulations of CATTSS using user approval on subword spotting results. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used.\relax }{table.caption.43}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}CAT Through Unassisted Subword Spotting Using Dynamic Time-Warping Alignment Results}{66}{subsection.7.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Part of a page of the Bentham dataset after running the CATTSS system with subword spotting approval being distributied using a two-distribution model with only bigrams. The pink boxes represent approved bigram spottings. The red text represents a transcription made by the system.\relax }}{67}{figure.caption.44}}
\newlabel{fig:aftercattss}{{7.1}{67}{Part of a page of the Bentham dataset after running the CATTSS system with subword spotting approval being distributied using a two-distribution model with only bigrams. The pink boxes represent approved bigram spottings. The red text represents a transcription made by the system.\relax }{figure.caption.44}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7.3}{\ignorespaces Results from simulations using character probability vectors derived from subword spotting resutls. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used.\relax }}{68}{table.caption.45}}
\newlabel{tab:dtwresults}{{7.3}{68}{Results from simulations using character probability vectors derived from subword spotting resutls. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used.\relax }{table.caption.45}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Conclusion}{69}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Contributions}{69}{section.8.1}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Future Work}{70}{section.8.2}}
\bibstyle{plainnat}
\bibdata{bib}
\bibcite{Aldavert2015}{{1}{2015}{{Aldavert et~al.}}{{Aldavert, Rusi\={n}ol, Toledo, and Llad\'{o}s}}}
\bibcite{Almazan2012}{{2}{2012}{{Almaz\'{a}n et~al.}}{{Almaz\'{a}n, Fern\'{a}ndez, Forn\'{e}s, Llados, and Valveny}}}
\bibcite{Almazan2014}{{3}{2014}{{Almaz\'{a}n et~al.}}{{Almaz\'{a}n, Gordo, Forn\'{e}s, and Valveny}}}
\bibcite{Bunke2004}{{4}{2004}{{Bunke et~al.}}{{Bunke, Bengio, and Vinciarelli}}}
\bibcite{Clawson2014}{{5}{2014}{{Clawson}}{{}}}
\bibcite{Fischer2012}{{6}{2012}{{Fischer et~al.}}{{Fischer, Keller, Frinken, and Bunke}}}
\bibcite{bentham}{{7}{2014}{{Gatos et~al.}}{{Gatos, Louloudis, Causer, Grint, Romero, S\'{a}nchez, Toselli, and Vidal}}}
\bibcite{CTC}{{8}{2006}{{Graves et~al.}}{{Graves, Fern獺ndez, and Gomez}}}
\@writefile{toc}{\contentsline {chapter}{References}{73}{toclistings.3}}
\bibcite{SPP}{{9}{2015}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{caffe}{{10}{2014}{{Jia et~al.}}{{Jia, Shelhamer, Donahue, Karayev, Long, Girshick, Guadarrama, and Darrell}}}
\bibcite{adam}{{11}{2015}{{Kingma and Ba}}{{}}}
\bibcite{krishnan2016}{{12}{2016}{{Krishnan et~al.}}{{Krishnan, Dutta, and Jawahar}}}
\bibcite{liang2012}{{13}{2012}{{Liang et~al.}}{{Liang, Fairhurst, and Guest}}}
\bibcite{manmatha1996}{{14}{1996}{{Manmatha et~al.}}{{Manmatha, Han, and Riseman}}}
\bibcite{IAM}{{15}{2002}{{Marti and Bunke}}{{}}}
\bibcite{Marti2001}{{16}{2001}{{Marti and Bunke}}{{}}}
\bibcite{Neudecker2010}{{17}{2010}{{Neudecker and Tzadok}}{{}}}
\bibcite{puigcerver2017}{{18}{2017}{{Puigcerver}}{{}}}
\bibcite{Rath2003}{{19}{2003}{{Rath and Manmatha}}{{}}}
\bibcite{Retsinas2015}{{20}{2015}{{Retsinas et~al.}}{{Retsinas, Gatos, Antonacopoulos, Louloudis, and Stamatopoulos}}}
\bibcite{retsinasTrans2017}{{21}{2017}{{Retsinas et~al.}}{{Retsinas, Sfikas, and Gatos}}}
\bibcite{Rodr覺guez2008}{{22}{2008}{{Rodr{\i }guez. and Perronnin}}{{}}}
\bibcite{Toselli2009}{{23}{2009}{{Romero et~al.}}{{Romero, Toselli, Rodriguez, and Vidal}}}
\bibcite{Rothacker2013}{{24}{2013}{{Rothacker et~al.}}{{Rothacker, Rusi{\~{n}ol}, and Fink}}}
\bibcite{icdarComp2017}{{25}{2017}{{S\'{a}nchez et~al.}}{{S\'{a}nchez, Romero, Toselli, Villegas, and Vidal}}}
\bibcite{Serrano2010}{{26}{2010}{{Serrano et~al.}}{{Serrano, Gim{\'e}nez, Sanchis, and Juan}}}
\bibcite{Serrano2014}{{27}{2014}{{Serrano et~al.}}{{Serrano, Gim\'{e}nez, Civera, Sanchis, and Juan}}}
\bibcite{Shekhar2012}{{28}{2012}{{Shekhar and Jawahar}}{{}}}
\bibcite{sudholt2016}{{29}{2016}{{Sudholt and Fink}}{{}}}
\bibcite{sudholt2017}{{30}{2017}{{Sudholt and Fink}}{{}}}
\bibcite{icfhrComp2016}{{31}{2016}{{S獺nchez et~al.}}{{S獺nchez, Romero, Toselli, and Vidal}}}
\bibcite{Toselli2007}{{32}{2007}{{Toselli et~al.}}{{Toselli, Romero, Rodriguez, and Vidal}}}
\bibcite{Toselli2010}{{33}{2010}{{Toselli et~al.}}{{Toselli, Romero, Pastor, , and Vidal}}}
\bibcite{Toselli2008}{{34}{2008}{{Toselli et~al.}}{{Toselli, Romero, and Vidal}}}
\bibcite{wigington2017}{{35}{2017}{{Wigington et~al.}}{{Wigington, Stewart, Davis, and Barrett}}}
\bibcite{wilkinson2017}{{36}{2017}{{Wilkinson et~al.}}{{Wilkinson, Lindstr{\"{o}}m, and Brun}}}
\bibcite{Zagoris2015}{{37}{2015}{{Zagoris et~al.}}{{Zagoris, Pratikakis, and Gatos}}}
