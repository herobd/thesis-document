\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{icdarComp2017}
\citation{icdarComp2017}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{ix}{toclistings.1}}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Retsinas2015}
\citation{Retsinas2015}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{xv}{toclistings.2}}
\citation{icfhrComp2016,wigington2017,icdarComp2017}
\citation{icfhrComp2016}
\citation{icdarComp2017}
\citation{wigington2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{manmatha1996}
\citation{manmatha1996}
\citation{liang2012}
\citation{liang2012}
\citation{Clawson2014}
\citation{Clawson2014}
\citation{Zagoris2015}
\citation{Zagoris2015}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Examples of word spotting for `pay' and `payment'.\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:explain_spotting}{{1.1}{2}{Examples of word spotting for `pay' and `payment'.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Examples of subword spotting for the character trigram `pay' (left, red) and bigram `pa' (right, yellow).\relax }}{2}{figure.caption.2}}
\newlabel{fig:explain_sub_spotting}{{1.2}{2}{Examples of subword spotting for the character trigram `pay' (left, red) and bigram `pa' (right, yellow).\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Why Subword Spotting?}{3}{section.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Cropped examples of the characters ``e'' and ``i'' (excluding dots), on the left and right respectively, from a single author. Without context the characters are practically indistinguishable.\relax }}{4}{figure.caption.3}}
\newlabel{fig:ei}{{1.3}{4}{Cropped examples of the characters ``e'' and ``i'' (excluding dots), on the left and right respectively, from a single author. Without context the characters are practically indistinguishable.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces An example of a word having ``pa'' and ``men'' spotted in it. A regular expression representing this, \texttt  {pa..?men..?}, yields only a few matches from our lexicon, including the correct one: ``pavement'', ``pavements'', ``\textbf  {payment}'', and ``payments''.\relax }}{5}{figure.caption.4}}
\newlabel{fig:subtransexample}{{1.4}{5}{An example of a word having ``pa'' and ``men'' spotted in it. A regular expression representing this, \texttt {pa..?men..?}, yields only a few matches from our lexicon, including the correct one: ``pavement'', ``pavements'', ``\textbf {payment}'', and ``payments''.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Main Contributions}{5}{section.1.2}}
\citation{Rodr覺guez2008}
\citation{Rodr覺guez2008}
\citation{Shekhar2012}
\citation{Shekhar2012}
\citation{Rothacker2013}
\citation{Rothacker2013}
\citation{Rodr覺guez2008}
\citation{Rodr覺guez2008}
\citation{Rath2003}
\citation{Rath2003}
\citation{Marti2001}
\citation{Marti2001}
\citation{Bunke2004}
\citation{Bunke2004}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{relatedwork}{{2}{7}{Related Work}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Word Spotting}{7}{section.2.1}}
\newlabel{relatedwork_wordspotting}{{2.1}{7}{Word Spotting}{section.2.1}{}}
\citation{Aldavert2015}
\citation{Aldavert2015}
\citation{Almazan2014}
\citation{Almazan2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of how vertical slice window features are extracted. Typically most features are extracted on a binarized image (a). Deskewing the image (b) plays an important role as the vertical slices are very sensitive to skew. Many typical features extracted (c) are pixel counts; in this example we show count features dependent on baselines (blue).\relax }}{8}{figure.caption.5}}
\newlabel{fig:vertslice}{{2.1}{8}{Example of how vertical slice window features are extracted. Typically most features are extracted on a binarized image (a). Deskewing the image (b) plays an important role as the vertical slices are very sensitive to skew. Many typical features extracted (c) are pixel counts; in this example we show count features dependent on baselines (blue).\relax }{figure.caption.5}{}}
\citation{sudholt2016,sudholt2017}
\citation{sudholt2016}
\citation{sudholt2017}
\citation{Almazan2014}
\citation{Almazan2014}
\citation{krishnan2016,retsinasTrans2017}
\citation{krishnan2016}
\citation{retsinasTrans2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{wilkinson2017}
\citation{wilkinson2017}
\citation{Rothacker2013}
\citation{Rothacker2013}
\citation{Fischer2012}
\citation{Fischer2012}
\citation{Almazan2012}
\citation{Almazan2012}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a three-level PHOC vector for the word ``face''. The final vector is all levels appended together. Note that partial values are given when characters are split over bins.\relax }}{9}{figure.caption.6}}
\newlabel{fig:phoc}{{2.2}{9}{Example of a three-level PHOC vector for the word ``face''. The final vector is all levels appended together. Note that partial values are given when characters are split over bins.\relax }{figure.caption.6}{}}
\citation{CTC}
\citation{CTC}
\citation{icdarComp2017}
\citation{icdarComp2017}
\citation{wigington2017,puigcerver2017}
\citation{puigcerver2017}
\citation{wigington2017}
\citation{icdarComp2017}
\citation{icdarComp2017}
\citation{icdarComp2017}
\citation{icdarComp2017}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Automatic Handwriting Recognition}{10}{section.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Computer Assisted Transcription}{10}{section.2.3}}
\citation{Serrano2010}
\citation{Serrano2010}
\citation{Toselli2007}
\citation{Toselli2007}
\citation{Toselli2008}
\citation{Toselli2008}
\citation{Toselli2009}
\citation{Toselli2009}
\citation{Toselli2010}
\citation{Toselli2010}
\citation{Serrano2014}
\citation{Serrano2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of lines extracted from the dataset of the ICDAR HTR competition \cite  {icdarComp2017}.\relax }}{11}{figure.caption.7}}
\newlabel{fig:germanlines}{{2.3}{11}{Example of lines extracted from the dataset of the ICDAR HTR competition \cite {icdarComp2017}.\relax }{figure.caption.7}{}}
\citation{Clawson2014}
\citation{Clawson2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces A screenshot of a demo of Toselli et al's multimodal CAT system. The red line is drawn by the user to indicate the need to insert a word into the automatically obtained transcription.\relax }}{12}{figure.caption.8}}
\newlabel{fig:Toselli_multimodalCAT}{{2.4}{12}{A screenshot of a demo of Toselli et al's multimodal CAT system. The red line is drawn by the user to indicate the need to insert a word into the automatically obtained transcription.\relax }{figure.caption.8}{}}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Zagoris2015}
\citation{Neudecker2010}
\citation{Neudecker2010}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Clawson's CAT system for tabular documents.\relax }}{13}{figure.caption.9}}
\newlabel{fig:ii}{{2.5}{13}{Clawson's CAT system for tabular documents.\relax }{figure.caption.9}{}}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Retsinas2015}
\citation{Retsinas2015}
\citation{Neudecker2010}
\citation{Neudecker2010}
\citation{Clawson2014}
\citation{Clawson2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces A screen-shot of a the CAT system of Zagoris et al.\nobreakspace  {}\cite  {Zagoris2015}. The green text indicates hand labeling, the blue text indicates automatic labeling. You can see to the right of the current word (``must'') the current ranked list of spottings (blue boxes).\relax }}{14}{figure.caption.10}}
\newlabel{fig:zagoris}{{2.6}{14}{A screen-shot of a the CAT system of Zagoris et al.~\cite {Zagoris2015}. The green text indicates hand labeling, the blue text indicates automatic labeling. You can see to the right of the current word (``must'') the current ranked list of spottings (blue boxes).\relax }{figure.caption.10}{}}
\citation{Retsinas2015}
\citation{Retsinas2015}
\citation{Retsinas2015}
\citation{Retsinas2015}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces A screen-shot of a character session for ``?'' from Neudecker and Tzadok's CAT system \cite  {Neudecker2010}, taken directly from their report \cite  {Neudecker2010}. Notice how easy it is for a user to simply click on the erroneous classifications.\relax }}{15}{figure.caption.11}}
\newlabel{fig:carpet}{{2.7}{15}{A screen-shot of a character session for ``?'' from Neudecker and Tzadok's CAT system \cite {Neudecker2010}, taken directly from their report \cite {Neudecker2010}. Notice how easy it is for a user to simply click on the erroneous classifications.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Examples of a good cluster (`c') and an incoherent cluster (multiple character classes) taken from \cite  {Retsinas2015}.\relax }}{15}{figure.caption.12}}
\newlabel{fig:retsinas_ex}{{2.8}{15}{Examples of a good cluster (`c') and an incoherent cluster (multiple character classes) taken from \cite {Retsinas2015}.\relax }{figure.caption.12}{}}
\citation{IAM}
\citation{IAM}
\citation{bentham}
\citation{bentham}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Datasets}{17}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{datasets}{{3}{17}{Datasets}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}IAM Dataset}{17}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Bentham Dataset}{17}{section.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Examples of lines from the IAM dataset.\relax }}{18}{figure.caption.13}}
\newlabel{fig:IAMExamples}{{3.1}{18}{Examples of lines from the IAM dataset.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Census Names Dataset}{18}{section.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Excerpts from the Bentham dataset.\relax }}{19}{figure.caption.14}}
\newlabel{fig:BenthamExamples}{{3.2}{19}{Excerpts from the Bentham dataset.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Character Annotation}{20}{section.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Process for extracting names from US 1930 census forms for Census Names data set. We begin with registered forms (a). Then we average the images together (b). The average image is used to mark form boundaries manually (c). The lines are registered to specific census image (d). At each cell a peojection profile is computed around the cell boundaries (dark blue) (e). The cell boundaries are snapped to the histogram peaks (f). Word boundaries were manually annotated for each cell (g).\relax }}{21}{figure.caption.15}}
\newlabel{fig:makenames}{{3.3}{21}{Process for extracting names from US 1930 census forms for Census Names data set. We begin with registered forms (a). Then we average the images together (b). The average image is used to mark form boundaries manually (c). The lines are registered to specific census image (d). At each cell a peojection profile is computed around the cell boundaries (dark blue) (e). The cell boundaries are snapped to the histogram peaks (f). Word boundaries were manually annotated for each cell (g).\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Excerpts from the Census Names dataset.\relax }}{22}{figure.caption.16}}
\newlabel{fig:NamesExamples}{{3.4}{22}{Excerpts from the Census Names dataset.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Example of hand annotated character segmentation.\relax }}{22}{figure.caption.17}}
\newlabel{fig:charseg}{{3.5}{22}{Example of hand annotated character segmentation.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Lexicon}{23}{section.3.5}}
\citation{sudholt2016,sudholt2017}
\citation{sudholt2016}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{Almazan2014}
\citation{Almazan2014}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{Almazan2014}
\citation{Almazan2014}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Subword Spotting}{25}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{subwordspotting}{{4}{25}{Subword Spotting}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Implementation}{25}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Architecture}{25}{subsection.4.1.1}}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{caffe}
\citation{caffe}
\citation{SPP}
\citation{SPP}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{adam}
\citation{adam}
\citation{sudholt2017}
\citation{sudholt2017}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Network architecture for embedding images as PHOC vectors. The numbers beneath each layer represent the number of channels. As the network uses temporal pyramid pooling before the fully connected layers, it can accept images of any size. Our architecture differs from \cite  {sudholt2017} only in the number of channels of the last convolutional layer.\relax }}{27}{figure.caption.18}}
\newlabel{fig:network}{{4.1}{27}{Network architecture for embedding images as PHOC vectors. The numbers beneath each layer represent the number of channels. As the network uses temporal pyramid pooling before the fully connected layers, it can accept images of any size. Our architecture differs from \cite {sudholt2017} only in the number of channels of the last convolutional layer.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Training}{27}{subsection.4.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Determining Window Widths}{27}{subsection.4.1.3}}
\newlabel{detirminewindowsize}{{4.1.3}{27}{Determining Window Widths}{subsection.4.1.3}{}}
\citation{sudholt2017}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces What temporal pyramid pooling (TPP) looks like visually. The same network features (large blocks) is divided into even horizontal windows of different counts (1,2,3,4,5 here). The result of pooling each of these windows (max pooling in our implementation) is appended together as an output vector. This is the red vector in Figure \ref  {fig:network}.\relax }}{28}{figure.caption.19}}
\newlabel{fig:TPP_example}{{4.2}{28}{What temporal pyramid pooling (TPP) looks like visually. The same network features (large blocks) is divided into even horizontal windows of different counts (1,2,3,4,5 here). The result of pooling each of these windows (max pooling in our implementation) is appended together as an output vector. This is the red vector in Figure \ref {fig:network}.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Running}{28}{subsection.4.1.4}}
\citation{sudholt2017}
\citation{Zagoris2015}
\citation{Zagoris2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Combining QbE Results}{29}{subsection.4.1.5}}
\newlabel{combine}{{4.1.5}{29}{Combining QbE Results}{subsection.4.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Analysis of Subword Spotting}{29}{section.4.2}}
\citation{sudholt2016}
\citation{sudholt2016}
\citation{sudholt2016,sudholt2017}
\citation{sudholt2016}
\citation{sudholt2017}
\citation{sudholt2016}
\citation{sudholt2016}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces MAP for full word spotting results, reported for both query-by-string (QbS) and query-by-example (QbE).\relax }}{30}{table.caption.20}}
\newlabel{tab:wordspottingresults}{{4.1}{30}{MAP for full word spotting results, reported for both query-by-string (QbS) and query-by-example (QbE).\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Full Word Spotting}{30}{subsection.4.2.1}}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\citation{sudholt2017}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces MAP for subword spotting results on the Bentham and Census Names datasets, reported for query-by-string (QbS) and, query-by-example (QbE).\relax }}{31}{table.caption.21}}
\newlabel{tab:subwordspotting}{{4.2}{31}{MAP for subword spotting results on the Bentham and Census Names datasets, reported for query-by-string (QbS) and, query-by-example (QbE).\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Subword Spotting}{31}{subsection.4.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Qualitative results for QbS subword spotting on the Bentham Dataset. Spottings show the top results for the various n-gram queries. We selected some of the better n-grams (`s', `th', `but') and worse n-grams (`j', `et', `tin') by MAP. Red boxes indicate incorrect spottings. \relax }}{32}{figure.caption.23}}
\newlabel{fig:qualSpot}{{4.3}{32}{Qualitative results for QbS subword spotting on the Bentham Dataset. Spottings show the top results for the various n-gram queries. We selected some of the better n-grams (`s', `th', `but') and worse n-grams (`j', `et', `tin') by MAP. Red boxes indicate incorrect spottings. \relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Qualitative results for QbS subword spotting on the Census Names Dataset. Spottings show the top results for the various n-gram queries. We selected some of the better n-grams (`i', `el', `int') and worse n-grams (`v', `ts', `pre') by MAP. Red boxes indicate incorrect spottings. \relax }}{33}{figure.caption.24}}
\newlabel{fig:qualSpotNames}{{4.4}{33}{Qualitative results for QbS subword spotting on the Census Names Dataset. Spottings show the top results for the various n-gram queries. We selected some of the better n-grams (`i', `el', `int') and worse n-grams (`v', `ts', `pre') by MAP. Red boxes indicate incorrect spottings. \relax }{figure.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces MAP for subword spotting results on the Bentham dataset using cosine similarity and cross-entropy (CE) similarity and networks trained with the PHOC used in \cite  {sudholt2017} and an adapted PHOC for subword spotting. In some experiments parts of the PHOC vectors were masked which were uninformative to the given task.\relax }}{34}{table.caption.22}}
\newlabel{tab:distmetrics}{{4.3}{34}{MAP for subword spotting results on the Bentham dataset using cosine similarity and cross-entropy (CE) similarity and networks trained with the PHOC used in \cite {sudholt2017} and an adapted PHOC for subword spotting. In some experiments parts of the PHOC vectors were masked which were uninformative to the given task.\relax }{table.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces This shows a word image with windows of various widths: 200-red, 150-green, 100-blue, 50-yellow, 25-cyan. \relax }}{36}{figure.caption.25}}
\newlabel{fig:exampleWindows}{{4.5}{36}{This shows a word image with windows of various widths: 200-red, 150-green, 100-blue, 50-yellow, 25-cyan. \relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces These shows the QbS MAP for 18 n-grams on the Bentham dataset for varying sliding window sizes (in pixels). Figure \ref  {fig:exampleWindows} shows examples of what these windows might look like. \relax }}{36}{figure.caption.25}}
\newlabel{fig:windowsizes}{{4.6}{36}{These shows the QbS MAP for 18 n-grams on the Bentham dataset for varying sliding window sizes (in pixels). Figure \ref {fig:exampleWindows} shows examples of what these windows might look like. \relax }{figure.caption.25}{}}
\newlabel{fig:benthamUniSpot}{{4.7a}{37}{Unigrams\relax }{figure.caption.26}{}}
\newlabel{sub@fig:benthamUniSpot}{{a}{37}{Unigrams\relax }{figure.caption.26}{}}
\newlabel{fig:benthamBiSpot}{{4.7b}{37}{Bigrams\relax }{figure.caption.26}{}}
\newlabel{sub@fig:benthamBiSpot}{{b}{37}{Bigrams\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Results for QbS unigram and bigram spotting on the Bentham dataset. N-grams are arrange in descending order of frequency in test set.\relax }}{37}{figure.caption.26}}
\newlabel{fig:benthamsub}{{4.7}{37}{Results for QbS unigram and bigram spotting on the Bentham dataset. N-grams are arrange in descending order of frequency in test set.\relax }{figure.caption.26}{}}
\newlabel{fig:benthamTri1Spot}{{\caption@xref {fig:benthamTri1Spot}{ on input line 925}}{38}{Subword Spotting}{figure.caption.27}{}}
\newlabel{sub@fig:benthamTri1Spot}{{}{38}{Subword Spotting}{figure.caption.27}{}}
\newlabel{fig:benthamTri2Spot}{{\caption@xref {fig:benthamTri2Spot}{ on input line 931}}{38}{Subword Spotting}{figure.caption.27}{}}
\newlabel{sub@fig:benthamTri2Spot}{{}{38}{Subword Spotting}{figure.caption.27}{}}
\newlabel{fig:benthamTri3Spot}{{\caption@xref {fig:benthamTri3Spot}{ on input line 937}}{38}{Subword Spotting}{figure.caption.27}{}}
\newlabel{sub@fig:benthamTri3Spot}{{}{38}{Subword Spotting}{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Results for QbS trigram spotting on the Bentham dataset. N-grams are arrange in descending order of frequency in test set.\relax }}{38}{figure.caption.27}}
\newlabel{fig:benthamsub2}{{4.8}{38}{Results for QbS trigram spotting on the Bentham dataset. N-grams are arrange in descending order of frequency in test set.\relax }{figure.caption.27}{}}
\newlabel{fig:namesUniSpot}{{4.9a}{39}{Unigrams\relax }{figure.caption.28}{}}
\newlabel{sub@fig:namesUniSpot}{{a}{39}{Unigrams\relax }{figure.caption.28}{}}
\newlabel{fig:namesBiSpot}{{4.9b}{39}{Bigrams\relax }{figure.caption.28}{}}
\newlabel{sub@fig:namesBiSpot}{{b}{39}{Bigrams\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Results for QbS unigram and bigram spotting on the Census Names dataset. N-grams are arrange in descending order of frequency in test set.\relax }}{39}{figure.caption.28}}
\newlabel{fig:namessub}{{4.9}{39}{Results for QbS unigram and bigram spotting on the Census Names dataset. N-grams are arrange in descending order of frequency in test set.\relax }{figure.caption.28}{}}
\newlabel{fig:namesTri1Spot}{{\caption@xref {fig:namesTri1Spot}{ on input line 967}}{40}{Subword Spotting}{figure.caption.29}{}}
\newlabel{sub@fig:namesTri1Spot}{{}{40}{Subword Spotting}{figure.caption.29}{}}
\newlabel{fig:namesTri2Spot}{{\caption@xref {fig:namesTri2Spot}{ on input line 973}}{40}{Subword Spotting}{figure.caption.29}{}}
\newlabel{sub@fig:namesTri2Spot}{{}{40}{Subword Spotting}{figure.caption.29}{}}
\newlabel{fig:namesTri3Spot}{{\caption@xref {fig:namesTri3Spot}{ on input line 979}}{40}{Subword Spotting}{figure.caption.29}{}}
\newlabel{sub@fig:namesTri3Spot}{{}{40}{Subword Spotting}{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Results for QbS trigram spotting on the Census Names dataset. N-grams are arrange in descending order of frequency in test set.\relax }}{40}{figure.caption.29}}
\newlabel{fig:namessub2}{{4.10}{40}{Results for QbS trigram spotting on the Census Names dataset. N-grams are arrange in descending order of frequency in test set.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Respotting Subwords}{41}{subsection.4.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Unigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{42}{figure.caption.30}}
\newlabel{fig:unigram_respot}{{4.11}{42}{Unigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Bigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{42}{figure.caption.31}}
\newlabel{fig:bigram_respot}{{4.12}{42}{Bigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Trigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{43}{figure.caption.32}}
\newlabel{fig:trigram_respot}{{4.13}{43}{Trigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Applications of Subword Spotting}{45}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{applications}{{5}{45}{Applications of Subword Spotting}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Manual Transcription Assistant}{45}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Suffix Spotting}{46}{section.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Transcription assistance using subword spotting. (a) The user selects an unknown character (``G'', red box) to search the documents. (b) The results of a QbE search are displayed, strength of highlight relative to spotting score. (c) A ranked list of matches is shown (best match at top). The user selects another instance to refine the results (blue arrow). (d) Combined QbE results. Exemplars are highlighted in blue. (e) Ranked combined results, a more common word, ``Grace'' (red arrow), has moved up to a more visible position.\relax }}{47}{figure.caption.33}}
\newlabel{fig:assist_demo}{{5.1}{47}{Transcription assistance using subword spotting. (a) The user selects an unknown character (``G'', red box) to search the documents. (b) The results of a QbE search are displayed, strength of highlight relative to spotting score. (c) A ranked list of matches is shown (best match at top). The user selects another instance to refine the results (blue arrow). (d) Combined QbE results. Exemplars are highlighted in blue. (e) Ranked combined results, a more common word, ``Grace'' (red arrow), has moved up to a more visible position.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Suffix spotting AP of individual suffixes for the IAM dataset. Arranged in descending order of frequency in test set.\relax }}{48}{figure.caption.34}}
\newlabel{fig:IAM_suffix}{{5.2}{48}{Suffix spotting AP of individual suffixes for the IAM dataset. Arranged in descending order of frequency in test set.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Suffix spotting AP of individual suffixes for the Census Names dataset. Arranged in descending order of frequency in test set.\relax }}{49}{figure.caption.35}}
\newlabel{fig:names_suffix}{{5.3}{49}{Suffix spotting AP of individual suffixes for the Census Names dataset. Arranged in descending order of frequency in test set.\relax }{figure.caption.35}{}}
\citation{krishnan2016}
\citation{krishnan2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Application of Subword Spotting to Transcription}{51}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{transcription}{{6}{51}{Application of Subword Spotting to Transcription}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Baseline: CAT Through PHOC Vectors}{51}{section.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces An overview of the CAT system which uses approved subword spottings. The arrows represent the flow of data. (a) Subword spotting is performed. (b) Spotting results are sorted and distributed as batches. (c) Users classify the spottings. (d) The spottings are aggregated into a regular expression. This yields a set of possible transcriptions in the lexicon. These are scored by performing word spotting on the word image. (e) The (reduced) list of possible transcriptions is sent to a user to selects the correct one.\relax }}{52}{figure.caption.36}}
\newlabel{fig:flow}{{6.1}{52}{An overview of the CAT system which uses approved subword spottings. The arrows represent the flow of data. (a) Subword spotting is performed. (b) Spotting results are sorted and distributed as batches. (c) Users classify the spottings. (d) The spottings are aggregated into a regular expression. This yields a set of possible transcriptions in the lexicon. These are scored by performing word spotting on the word image. (e) The (reduced) list of possible transcriptions is sent to a user to selects the correct one.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}CAT Through Approved Subword Spottings}{52}{section.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Subword Spotting}{53}{subsection.6.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}User Tasks and Interface}{53}{subsection.6.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2.1}Approval}{54}{subsubsection.6.2.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2.2}Transcription Selection}{54}{subsubsection.6.2.2.2}}
\newlabel{transtask}{{6.2.2.2}{54}{Transcription Selection}{subsubsection.6.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Spotting approval UI. Instance being classified is at the bottom of the interface (dark border). The desired label ``and'' is below it. The first two instances displayed are incorrect and the thrid is correct. The next label ``ing'' can be seen above these with its associated instances above it (two correct instances visible). \relax }}{55}{figure.caption.37}}
\newlabel{fig:spottingapproval}{{6.2}{55}{Spotting approval UI. Instance being classified is at the bottom of the interface (dark border). The desired label ``and'' is below it. The first two instances displayed are incorrect and the thrid is correct. The next label ``ing'' can be seen above these with its associated instances above it (two correct instances visible). \relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Word Completion / Regular Expression Generation}{56}{subsection.6.2.3}}
\newlabel{wordcompletion}{{6.2.3}{56}{Word Completion / Regular Expression Generation}{subsection.6.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Transcription selection UI. Both ``her'' and ``for'' have been spotted correctly in the image. The user can remove spottings if they are incorrect (red `x's). The possible transcriptions are ordered according to their word spotting score; in many instances this puts the correct transcription at the top of the list. \relax }}{57}{figure.caption.38}}
\newlabel{fig:transcriptionselection}{{6.3}{57}{Transcription selection UI. Both ``her'' and ``for'' have been spotted correctly in the image. The user can remove spottings if they are incorrect (red `x's). The possible transcriptions are ordered according to their word spotting score; in many instances this puts the correct transcription at the top of the list. \relax }{figure.caption.38}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Regular expression generation from spottings\relax }}{58}{algocf.1}}
\newlabel{regex}{{1}{58}{Word Completion / Regular Expression Generation}{algocf.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Transcription batch generation\relax }}{60}{algocf.2}}
\newlabel{batchGen}{{2}{60}{Word Completion / Regular Expression Generation}{algocf.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Receiving Transcription}{61}{subsection.6.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.5}Batch Distribution}{61}{subsection.6.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Histograms of spotting instances for the trigram ``and''. The left chart shows the instances aggregated as well as the fitted parabola. The right chart shows the true and false spottings seperated. Note the clear seperation being modeled by the parabola. \relax }}{62}{figure.caption.39}}
\newlabel{fig:two_dist_ex}{{6.4}{62}{Histograms of spotting instances for the trigram ``and''. The left chart shows the instances aggregated as well as the fitted parabola. The right chart shows the true and false spottings seperated. Note the clear seperation being modeled by the parabola. \relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Histograms of spotting instances for the bigram ``ti''. The left chart shows the instances aggregated as well as the fitted parabola. The right chart shows the true and false spottings seperated. Note that there is no clean division and the parabola's vertex falls outside the data range. \relax }}{63}{figure.caption.40}}
\newlabel{fig:one_dist_ex}{{6.5}{63}{Histograms of spotting instances for the bigram ``ti''. The left chart shows the instances aggregated as well as the fitted parabola. The right chart shows the true and false spottings seperated. Note that there is no clean division and the parabola's vertex falls outside the data range. \relax }{figure.caption.40}{}}
\citation{Retsinas2015}
\citation{Retsinas2015}
\citation{Clawson2014}
\citation{Clawson2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.6}Receiving Spotting Approvals}{64}{subsection.6.2.6}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}CAT Through Approved Subword Spottings Using Clustering}{64}{section.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Clustering}{65}{subsection.6.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Spotting Approval Batch Distribution}{65}{subsection.6.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces The cluster spotting approval UI with a true cluster. One outlier has been identified by the user (darkened instance).\relax }}{66}{figure.caption.41}}
\newlabel{fig:clustergood}{{6.6}{66}{The cluster spotting approval UI with a true cluster. One outlier has been identified by the user (darkened instance).\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces The cluster spotting approval UI with a false cluster. No outliers are present, all instances are incorrect.\relax }}{67}{figure.caption.42}}
\newlabel{fig:clusterbad}{{6.7}{67}{The cluster spotting approval UI with a false cluster. No outliers are present, all instances are incorrect.\relax }{figure.caption.42}{}}
\citation{Clawson2014}
\citation{Clawson2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Spotting Approval UI}{68}{subsection.6.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}CAT Through Unassisted Subword Spotting Using Dynamic Time-Warping Alignment}{68}{section.6.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces An example of a character probability vector for the word ``adultery''. The relative probability of each character (`a'-`z') at each horizontal position is represented both by the height and color of the graph. The discontinuities occuring at the begining and end of the word (e.g. see `x') occur due to the merging of unigram, bigram, and trigram scores.\relax }}{70}{figure.caption.43}}
\newlabel{fig:cpv}{{6.8}{70}{An example of a character probability vector for the word ``adultery''. The relative probability of each character (`a'-`z') at each horizontal position is represented both by the height and color of the graph. The discontinuities occuring at the begining and end of the word (e.g. see `x') occur due to the merging of unigram, bigram, and trigram scores.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Evaluation of Transcription Strategies}{71}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Evaluation Method}{71}{section.7.1}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Results}{72}{section.7.2}}
\@writefile{lot}{\contentsline {table}{\numberline {7.1}{\ignorespaces Highlights in the results from simulations. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used. The PHOC vector method is the only method we tested able to transcribe words at a rate faster than manual transcription.\relax }}{73}{table.caption.44}}
\newlabel{tab:finalresults}{{7.1}{73}{Highlights in the results from simulations. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used. The PHOC vector method is the only method we tested able to transcribe words at a rate faster than manual transcription.\relax }{table.caption.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}CAT Through PHOC Vectors Results}{73}{subsection.7.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}CAT Through Approved Subword Spottings Results}{73}{subsection.7.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {7.2}{\ignorespaces Results from simulations of CATTSS using user approval on subword spotting results. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used.\relax }}{74}{table.caption.45}}
\newlabel{tab:appresults}{{7.2}{74}{Results from simulations of CATTSS using user approval on subword spotting results. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used.\relax }{table.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Part of a page of the Bentham dataset after running the CATTSS system with subword spotting approval being distributied using a two-distribution model with only bigrams. The pink boxes represent approved bigram spottings. The red text represents a transcription made by the system.\relax }}{75}{figure.caption.46}}
\newlabel{fig:aftercattss}{{7.1}{75}{Part of a page of the Bentham dataset after running the CATTSS system with subword spotting approval being distributied using a two-distribution model with only bigrams. The pink boxes represent approved bigram spottings. The red text represents a transcription made by the system.\relax }{figure.caption.46}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7.3}{\ignorespaces Results from simulations using character probability vectors derived from subword spotting resutls. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used.\relax }}{76}{table.caption.47}}
\newlabel{tab:dtwresults}{{7.3}{76}{Results from simulations using character probability vectors derived from subword spotting resutls. The letters U, B and T represent whether unigrams, bigrams and/or trigrams were used.\relax }{table.caption.47}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}CAT Through Unassisted Subword Spotting Using Dynamic Time-Warping Alignment Results}{76}{subsection.7.2.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Conclusion}{77}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Contributions}{77}{section.8.1}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Future Work}{78}{section.8.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Appendix}{81}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\gdef \LT@i {\LT@entry 
    {1}{48.55519pt}\LT@entry 
    {1}{89.35336pt}\LT@entry 
    {1}{94.41026pt}\LT@entry 
    {1}{89.35336pt}\LT@entry 
    {1}{94.41026pt}}
\bibstyle{plainnat}
\bibdata{bib}
\@writefile{lot}{\contentsline {table}{\numberline {9.1}{\ignorespaces Optimal sliding window widths for spotting and estimated visual widths for each n-gram of interest.}}{90}{table.9.1}}
\newlabel{tab:customwidths}{{9.1}{90}{Optimal sliding window widths for spotting and estimated visual widths for each n-gram of interest}{table.9.1}{}}
\bibcite{Aldavert2015}{{1}{2015}{{Aldavert et~al.}}{{Aldavert, Rusi\={n}ol, Toledo, and Llad\'{o}s}}}
\bibcite{Almazan2012}{{2}{2012}{{Almaz\'{a}n et~al.}}{{Almaz\'{a}n, Fern\'{a}ndez, Forn\'{e}s, Llados, and Valveny}}}
\bibcite{Almazan2014}{{3}{2014}{{Almaz\'{a}n et~al.}}{{Almaz\'{a}n, Gordo, Forn\'{e}s, and Valveny}}}
\bibcite{Bunke2004}{{4}{2004}{{Bunke et~al.}}{{Bunke, Bengio, and Vinciarelli}}}
\bibcite{Clawson2014}{{5}{2014}{{Clawson}}{{}}}
\bibcite{Fischer2012}{{6}{2012}{{Fischer et~al.}}{{Fischer, Keller, Frinken, and Bunke}}}
\bibcite{bentham}{{7}{2014}{{Gatos et~al.}}{{Gatos, Louloudis, Causer, Grint, Romero, S\'{a}nchez, Toselli, and Vidal}}}
\bibcite{CTC}{{8}{2006}{{Graves et~al.}}{{Graves, Fern\'{a}ndez, and Gomez}}}
\bibcite{SPP}{{9}{2015}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{caffe}{{10}{2014}{{Jia et~al.}}{{Jia, Shelhamer, Donahue, Karayev, Long, Girshick, Guadarrama, and Darrell}}}
\@writefile{toc}{\contentsline {chapter}{References}{91}{toclistings.3}}
\bibcite{adam}{{11}{2015}{{Kingma and Ba}}{{}}}
\bibcite{krishnan2016}{{12}{2016}{{Krishnan et~al.}}{{Krishnan, Dutta, and Jawahar}}}
\bibcite{liang2012}{{13}{2012}{{Liang et~al.}}{{Liang, Fairhurst, and Guest}}}
\bibcite{manmatha1996}{{14}{1996}{{Manmatha et~al.}}{{Manmatha, Han, and Riseman}}}
\bibcite{IAM}{{15}{2002}{{Marti and Bunke}}{{}}}
\bibcite{Marti2001}{{16}{2001}{{Marti and Bunke}}{{}}}
\bibcite{Neudecker2010}{{17}{2010}{{Neudecker and Tzadok}}{{}}}
\bibcite{puigcerver2017}{{18}{2017}{{Puigcerver}}{{}}}
\bibcite{Rath2003}{{19}{2003}{{Rath and Manmatha}}{{}}}
\bibcite{Retsinas2015}{{20}{2015}{{Retsinas et~al.}}{{Retsinas, Gatos, Antonacopoulos, Louloudis, and Stamatopoulos}}}
\bibcite{retsinasTrans2017}{{21}{2017}{{Retsinas et~al.}}{{Retsinas, Sfikas, and Gatos}}}
\bibcite{Rodr覺guez2008}{{22}{2008}{{Rodr{\i }guez. and Perronnin}}{{}}}
\bibcite{Toselli2009}{{23}{2009}{{Romero et~al.}}{{Romero, Toselli, Rodriguez, and Vidal}}}
\bibcite{Rothacker2013}{{24}{2013}{{Rothacker et~al.}}{{Rothacker, Rusi{\~{n}ol}, and Fink}}}
\bibcite{icfhrComp2016}{{25}{2016}{{S\'{a}nchez et~al.}}{{S\'{a}nchez, Romero, Toselli, and Vidal}}}
\bibcite{icdarComp2017}{{26}{2017}{{S\'{a}nchez et~al.}}{{S\'{a}nchez, Romero, Toselli, Villegas, and Vidal}}}
\bibcite{Serrano2010}{{27}{2010}{{Serrano et~al.}}{{Serrano, Gim{\'e}nez, Sanchis, and Juan}}}
\bibcite{Serrano2014}{{28}{2014}{{Serrano et~al.}}{{Serrano, Gim\'{e}nez, Civera, Sanchis, and Juan}}}
\bibcite{Shekhar2012}{{29}{2012}{{Shekhar and Jawahar}}{{}}}
\bibcite{sudholt2016}{{30}{2016}{{Sudholt and Fink}}{{}}}
\bibcite{sudholt2017}{{31}{2017}{{Sudholt and Fink}}{{}}}
\bibcite{Toselli2010}{{32}{2010}{{Toselli et~al.}}{{Toselli, Romero, Pastor, , and Vidal}}}
\bibcite{Toselli2007}{{33}{2007}{{Toselli et~al.}}{{Toselli, Romero, Rodriguez, and Vidal}}}
\bibcite{Toselli2008}{{34}{2008}{{Toselli et~al.}}{{Toselli, Romero, and Vidal}}}
\bibcite{wigington2017}{{35}{2017}{{Wigington et~al.}}{{Wigington, Stewart, Davis, and Barrett}}}
\bibcite{wilkinson2017}{{36}{2017}{{Wilkinson et~al.}}{{Wilkinson, Lindstr{\"{o}}m, and Brun}}}
\bibcite{Zagoris2015}{{37}{2015}{{Zagoris et~al.}}{{Zagoris, Pratikakis, and Gatos}}}
