\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Examples of word spotting for `pay' and `payment'.\relax }}{2}{figure.caption.1}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Examples of subword spotting for the character trigram `pay' (left, red) and bigram `pa' (right, yellow).\relax }}{2}{figure.caption.2}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Cropped examples of the characters ``e'' and ``i'' (excluding dots), on the left and right respectively, from a single author. Without context the characters are practically indistinguishable.\relax }}{4}{figure.caption.3}
\contentsline {figure}{\numberline {1.4}{\ignorespaces An example of a word having ``pa'' and ``men'' spotted in it. A regular expression representing this, \texttt {pa..?men..?}, yields only a few matches from our lexicon, including the correct one: ``pavement'', ``pavements'', ``\textbf {payment}'', and ``payments''.\relax }}{5}{figure.caption.4}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces A screenshot of a demo of Toselli et al's multimodal CAT system. The red line is drawn by the user to indicate the need to insert a word into the automatically obtained transcription.\relax }}{10}{figure.caption.5}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Clawson's CAT system for tabular documents.\relax }}{11}{figure.caption.6}
\contentsline {figure}{\numberline {2.3}{\ignorespaces A screen shot of a character session for ``?'' from Neudecker and Tzadok's CAT system, taken directly from their report \cite {Neudecker2010}. Notice how easy it is for a user to simply click on the erroneous classifications.\relax }}{13}{figure.caption.7}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Example of a PHOC vector for the word ``face''. The final vector is all levels appended together. Note that partial values are given when characters are split over bins.\relax }}{20}{figure.caption.8}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Network architecture for embedding images as PHOC vectors. The numbers beneath each layer represent the number of channels. As the network uses spatial pyramid pooling before the fully connected layers, it can accept images of any size.\relax }}{21}{figure.caption.9}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Example of data augmentation used in training.\relax }}{22}{figure.caption.10}
\contentsline {figure}{\numberline {4.4}{\ignorespaces MAP for QbS subword spotting results on the Bentham and Census Names datasets, where we only use n-grams in our query set which have an occurrence count above a threshold (in the testing sets). MAP increases, demonstrating less frequent n-grams are more difficult. Only trigrams are shown for the Bentham dataset due to the high frequency of all unigrams and bigrams.\relax }}{26}{figure.caption.13}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Unigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{27}{figure.caption.15}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Bigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{27}{figure.caption.16}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Trigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{28}{figure.caption.17}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces A figure with two subfigures\relax }}{30}{figure.caption.19}
\contentsline {figure}{\numberline {5.2}{\ignorespaces An overview of the CAT system which uses approved subword spottings. The arrows represent the flow of data.\relax }}{32}{figure.caption.20}
\addvspace {10\p@ }
