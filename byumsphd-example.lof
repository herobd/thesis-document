\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Examples of word spotting for `pay' and `payment'.\relax }}{2}{figure.caption.1}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Examples of subword spotting for the character trigram `pay' (left, red) and bigram `pa' (right, yellow).\relax }}{2}{figure.caption.2}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Cropped examples of the characters ``e'' and ``i'' (excluding dots), on the left and right respectively, from a single author. Without context the characters are practically indistinguishable.\relax }}{4}{figure.caption.3}
\contentsline {figure}{\numberline {1.4}{\ignorespaces An example of a word having ``pa'' and ``men'' spotted in it. A regular expression representing this, \texttt {pa..?men..?}, yields only a few matches from our lexicon, including the correct one: ``pavement'', ``pavements'', ``\textbf {payment}'', and ``payments''.\relax }}{5}{figure.caption.4}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of how vertical slice window features are extracted. Typically most features are extracted on a binarized image (a). Deskewing the image (b) plays an important role as the vertical slices are very sensitive to skew. Many typical features extracted (c) are pixel counts; in this example we show count features dependent on baselines (blue).\relax }}{8}{figure.caption.5}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a three-level PHOC vector for the word ``face''. The final vector is all levels appended together. Note that partial values are given when characters are split over bins.\relax }}{9}{figure.caption.6}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of lines extracted from the dataset of the ICDAR HTR competition \cite {icdarComp2017}.\relax }}{11}{figure.caption.7}
\contentsline {figure}{\numberline {2.4}{\ignorespaces A screenshot of a demo of Toselli et al's multimodal CAT system. The red line is drawn by the user to indicate the need to insert a word into the automatically obtained transcription.\relax }}{12}{figure.caption.8}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Clawson's CAT system for tabular documents.\relax }}{13}{figure.caption.9}
\contentsline {figure}{\numberline {2.6}{\ignorespaces A screen-shot of a the CAT system of Zagoris et al.\nobreakspace {}\cite {Zagoris2015}. The green text indicates hand labeling, the blue text indicates automatic labeling. You can see to the right of the current word (``must'') the current ranked list of spottings (blue boxes).\relax }}{14}{figure.caption.10}
\contentsline {figure}{\numberline {2.7}{\ignorespaces A screen-shot of a character session for ``?'' from Neudecker and Tzadok's CAT system \cite {Neudecker2010}, taken directly from their report \cite {Neudecker2010}. Notice how easy it is for a user to simply click on the erroneous classifications.\relax }}{15}{figure.caption.11}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Examples of a good cluster (`c') and an incoherent cluster (multiple character classes) taken from \cite {Retsinas2015}.\relax }}{15}{figure.caption.12}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Examples of lines from the IAM dataset.\relax }}{18}{figure.caption.13}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Excerpts from the Bentham dataset.\relax }}{19}{figure.caption.14}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Process for extracting names from US 1930 census forms for Census Names data set. We begin with registered forms (a). Then we average the images together (b). The average image is used to mark form boundaries manually (c). The lines are registered to specific census image (d). At each cell a peojection profile is computed around the cell boundaries (dark blue) (e). The cell boundaries are snapped to the histogram peaks (f). Word boundaries were manually annotated for each cell (g).\relax }}{21}{figure.caption.15}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Excerpts from the Census Names dataset.\relax }}{22}{figure.caption.16}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Example of hand annotated character segmentation.\relax }}{22}{figure.caption.17}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Network architecture for embedding images as PHOC vectors. The numbers beneath each layer represent the number of channels. As the network uses temporal pyramid pooling before the fully connected layers, it can accept images of any size. Our architecture differs from \cite {sudholt2017} only in the number of channels of the last convolutional layer.\relax }}{27}{figure.caption.18}
\contentsline {figure}{\numberline {4.2}{\ignorespaces What temporal pyramid pooling (TPP) looks like visually. The same network features (large blocks) is divided into even horizontal windows of different counts (1,2,3,4,5 here). The result of pooling each of these windows (max pooling in our implementation) is appended together as an output vector. This is the red vector in Figure \ref {fig:network}.\relax }}{28}{figure.caption.19}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Qualitative results for QbS subword spotting on the Bentham Dataset. Spottings show the top results for the various n-gram queries. We selected some of the better n-grams (`s', `th', `but') and worse n-grams (`j', `et', `tin') by MAP. Red boxes indicate incorrect spottings. \relax }}{32}{figure.caption.23}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Qualitative results for QbS subword spotting on the Census Names Dataset. Spottings show the top results for the various n-gram queries. We selected some of the better n-grams (`i', `el', `int') and worse n-grams (`v', `ts', `pre') by MAP. Red boxes indicate incorrect spottings. \relax }}{33}{figure.caption.24}
\contentsline {figure}{\numberline {4.5}{\ignorespaces This shows a word image with windows of various widths: 200-red, 150-green, 100-blue, 50-yellow, 25-cyan. \relax }}{36}{figure.caption.25}
\contentsline {figure}{\numberline {4.6}{\ignorespaces These shows the QbS MAP for 18 n-grams on the Bentham dataset for varying sliding window sizes (in pixels). Figure \ref {fig:exampleWindows} shows examples of what these windows might look like. \relax }}{36}{figure.caption.25}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Results for QbS unigram and bigram spotting on the Bentham dataset. N-grams are arrange in descending order of frequency in test set.\relax }}{37}{figure.caption.26}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Results for QbS trigram spotting on the Bentham dataset. N-grams are arrange in descending order of frequency in test set.\relax }}{38}{figure.caption.27}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Results for QbS unigram and bigram spotting on the Census Names dataset. N-grams are arrange in descending order of frequency in test set.\relax }}{39}{figure.caption.28}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Results for QbS trigram spotting on the Census Names dataset. N-grams are arrange in descending order of frequency in test set.\relax }}{40}{figure.caption.29}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Unigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{42}{figure.caption.30}
\contentsline {figure}{\numberline {4.12}{\ignorespaces Bigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{42}{figure.caption.31}
\contentsline {figure}{\numberline {4.13}{\ignorespaces Trigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{43}{figure.caption.32}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Transcription assistance using subword spotting. (a) The user selects an unknown character (``G'', red box) to search the documents. (b) The results of a QbE search are displayed, strength of highlight relative to spotting score. (c) A ranked list of matches is shown (best match at top). The user selects another instance to refine the results (blue arrow). (d) Combined QbE results. Exemplars are highlighted in blue. (e) Ranked combined results, a more common word, ``Grace'' (red arrow), has moved up to a more visible position.\relax }}{47}{figure.caption.33}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Suffix spotting AP of individual suffixes for the IAM dataset. Arranged in descending order of frequency in test set.\relax }}{48}{figure.caption.34}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Suffix spotting AP of individual suffixes for the Census Names dataset. Arranged in descending order of frequency in test set.\relax }}{49}{figure.caption.35}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces An overview of the CAT system which uses approved subword spottings. The arrows represent the flow of data. (a) Subword spotting is performed. (b) Spotting results are sorted and distributed as batches. (c) Users classify the spottings. (d) The spottings are aggregated into a regular expression. This yields a set of possible transcriptions in the lexicon. These are scored by performing word spotting on the word image. (e) The (reduced) list of possible transcriptions is sent to a user to selects the correct one.\relax }}{52}{figure.caption.36}
\contentsline {figure}{\numberline {6.2}{\ignorespaces Spotting approval UI. Instance being classified is at the bottom of the interface (dark border). The desired label ``and'' is below it. The first two instances displayed are incorrect and the thrid is correct. The next label ``ing'' can be seen above these with its associated instances above it (two correct instances visible). \relax }}{55}{figure.caption.37}
\contentsline {figure}{\numberline {6.3}{\ignorespaces Transcription selection UI. Both ``her'' and ``for'' have been spotted correctly in the image. The user can remove spottings if they are incorrect (red `x's). The possible transcriptions are ordered according to their word spotting score; in many instances this puts the correct transcription at the top of the list. \relax }}{57}{figure.caption.38}
\contentsline {figure}{\numberline {6.4}{\ignorespaces Histograms of spotting instances for the trigram ``and''. The left chart shows the instances aggregated as well as the fitted parabola. The right chart shows the true and false spottings seperated. Note the clear seperation being modeled by the parabola. \relax }}{62}{figure.caption.39}
\contentsline {figure}{\numberline {6.5}{\ignorespaces Histograms of spotting instances for the bigram ``ti''. The left chart shows the instances aggregated as well as the fitted parabola. The right chart shows the true and false spottings seperated. Note that there is no clean division and the parabola's vertex falls outside the data range. \relax }}{63}{figure.caption.40}
\contentsline {figure}{\numberline {6.6}{\ignorespaces The cluster spotting approval UI with a true cluster. One outlier has been identified by the user (darkened instance).\relax }}{66}{figure.caption.41}
\contentsline {figure}{\numberline {6.7}{\ignorespaces The cluster spotting approval UI with a false cluster. No outliers are present, all instances are incorrect.\relax }}{67}{figure.caption.42}
\contentsline {figure}{\numberline {6.8}{\ignorespaces An example of a character probability vector for the word ``adultery''. The relative probability of each character (`a'-`z') at each horizontal position is represented both by the height and color of the graph. The discontinuities occuring at the begining and end of the word (e.g. see `x') occur due to the merging of unigram, bigram, and trigram scores.\relax }}{70}{figure.caption.43}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Part of a page of the Bentham dataset after running the CATTSS system with subword spotting approval being distributied using a two-distribution model with only bigrams. The pink boxes represent approved bigram spottings. The red text represents a transcription made by the system.\relax }}{75}{figure.caption.46}
\addvspace {10\p@ }
\addvspace {10\p@ }
