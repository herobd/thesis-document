\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Examples of word spotting for `pay' and `payment'.\relax }}{2}{figure.caption.1}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Examples of subword spotting for the character trigram `pay' (left, red) and bigram `pa' (right, yellow).\relax }}{2}{figure.caption.2}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Cropped examples of the characters ``e'' and ``i'' (excluding dots), on the left and right respectively, from a single author. Without context the characters are practically indistinguishable.\relax }}{4}{figure.caption.3}
\contentsline {figure}{\numberline {1.4}{\ignorespaces An example of a word having ``pa'' and ``men'' spotted in it. A regular expression representing this, \texttt {pa..?men..?}, yields only a few matches from our lexicon, including the correct one: ``pavement'', ``pavements'', ``\textbf {payment}'', and ``payments''.\relax }}{5}{figure.caption.4}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of how vertical slice window features are extracted. Typically most features are extracted on a binarized image (a). Deskewing the image (b) plays an important role as the vertical slices are very sensitive to skew. Many typical features extracted (c) are pixel counts; in this example we show count features dependent on baselines (blue).\relax }}{8}{figure.caption.5}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a three-level PHOC vector for the word ``face''. The final vector is all levels appended together. Note that partial values are given when characters are split over bins.\relax }}{9}{figure.caption.6}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of lines extracted from the dataset of the ICDAR HTR competition \cite {icdarComp2017}.\relax }}{11}{figure.caption.7}
\contentsline {figure}{\numberline {2.4}{\ignorespaces A screenshot of a demo of Toselli et al's multimodal CAT system. The red line is drawn by the user to indicate the need to insert a word into the automatically obtained transcription.\relax }}{12}{figure.caption.8}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Clawson's CAT system for tabular documents.\relax }}{13}{figure.caption.9}
\contentsline {figure}{\numberline {2.6}{\ignorespaces A screen-shot of a the CAT system of Zagoris et al.\nobreakspace {}\cite {Zagoris2015}. The green text indicates hand labeling, the blue text indicates automatic labeling. You can see to the right of the current word (``must'') the current ranked list of spottings (blue boxes).\relax }}{14}{figure.caption.10}
\contentsline {figure}{\numberline {2.7}{\ignorespaces A screen-shot of a character session for ``?'' from Neudecker and Tzadok's CAT system \cite {Neudecker2010}, taken directly from their report \cite {Neudecker2010}. Notice how easy it is for a user to simply click on the erroneous classifications.\relax }}{15}{figure.caption.11}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Examples of a good cluster (`c') and an incoherent cluster (multiple character classes) taken from \cite {Retsinas2015}.\relax }}{15}{figure.caption.12}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Examples of lines from the IAM dataset.\relax }}{18}{figure.caption.13}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Excerpts from the Bentham dataset.\relax }}{19}{figure.caption.14}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Process for extracting names from US 1930 census forms for Census Names data set. We begin with registerd forms (a). Then we average the images together (b). The average image is used to mark form boundaries manually (c). The lines are registered to specific census image (d). At each cell a histogram is computed around the cell boundaries (dark blue) (e). The cell boundaries are snapped to the histogram peaks (f). Word boundaries were manually annotated for each cell (g).\relax }}{21}{figure.caption.15}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Excerpts from the Census Names dataset.\relax }}{22}{figure.caption.16}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Example of hand annotated character segmentation.\relax }}{22}{figure.caption.17}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Network architecture for embedding images as PHOC vectors. The numbers beneath each layer represent the number of channels. As the network uses temporal pyramid pooling before the fully connected layers, it can accept images of any size. Our archetivture differs from \cite {sudholt2017} only in the number of channels of the last convolutional layer.\relax }}{26}{figure.caption.18}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Qualitative results for QbS subword spotting on the Bentham Dataset. Spottings show represent the top result for the various n-gram queries. We selected some of the better n-grams (`n', `pr', `sed') and worse n-grams (`z', `et', `tte') by MAP. Red boxes indicate incorrect spottings. \relax }}{31}{figure.caption.21}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Qualitative results for QbS subword spotting on the Census Names Dataset. Spottings show represent the top result for the various n-gram queries. We selected some of the better n-grams (`m', `il', `hic') and worse n-grams (`y', `ss', `wer') by MAP. Red boxes indicate incorrect spottings. \relax }}{32}{figure.caption.22}
\contentsline {figure}{\numberline {4.4}{\ignorespaces This shows the QbS MAP for 18 n-grams on the Bentham dataset for varying sliding window sizes. \relax }}{33}{figure.caption.23}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Results for QbS subword spotting on the Bentham dataset. N-grams are arrange in descending order of frequency in test set. Trigrams are not displayed for space reasons.\relax }}{34}{figure.caption.24}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Results for QbS subword spotting on the Census Names dataset. N-grams are arrange in descending order of frequency in test set. Trigrams are not displayed for space reasons.\relax }}{35}{figure.caption.25}
\contentsline {figure}{\numberline {4.7}{\ignorespaces MAP for QbS subword spotting results for trigrams where we only use queries which have an occurrence count above a threshol1d (in the testing sets). MAP increases, demonstrating the least frequent n-grams are more difficult. Only trigrams are shown as the effect is more dramatic in these cases. A opposite trend is not observed for uni- or bigrams. \relax }}{36}{figure.caption.26}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Unigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{37}{figure.caption.27}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Bigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{38}{figure.caption.28}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Trigram MAP when spotting results of consecutive image queries are combine (blue). The red line represents QbS performance and the yellow the average performance of all 50 QbE queries.\relax }}{38}{figure.caption.29}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Transcription assistance using subword spotting. (a) The user selects an unknown character (``G'', red box) to search the documents. (b) The results of a QbE search are displayed, strength of highlight relative to spotting score. (c) A ranked list of matches is shown (best match at top). The user selects another instance to refine the results (blue arrow). (d) Combined QbE results. Exemplars are highlighted in blue. (e) Ranked combined results, a more common word, ``Grace'' (red arrow), has moved up to a more visible position.\relax }}{41}{figure.caption.30}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Suffix spotting AP of individual suffixes for the IAM dataset. Arranged in descending order of frequency in test set.\relax }}{42}{figure.caption.31}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Suffix spotting AP of individual suffixes for the Census Names dataset. Arranged in descending order of frequency in test set.\relax }}{43}{figure.caption.32}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces An overview of the CAT system which uses approved subword spottings. The arrows represent the flow of data. (a) Subword spotting is performed. (b) Spotting results are sorted an distributed as batches. (c) Users classify the spottings. (d) The spottings are aggregated into a regular expression. This yields a set of possible transcriptions in the lexicon. These are scored with word spotting on the word image. (e) The (reduced) list of possible transcriptions is sent to a user to selects the correct one.\relax }}{46}{figure.caption.33}
\contentsline {figure}{\numberline {6.2}{\ignorespaces Spotting approval UI. Instance being classified is at the bottom of the interface (dark border). The desired label ``and'' is below it. The next label ``ing'' can be seen above it with its associated instances above it. \relax }}{49}{figure.caption.34}
\contentsline {figure}{\numberline {6.3}{\ignorespaces Transcription selection UI. Both ``her'' and ``for'' have been spotted in the image. The user can remove spottings if they are incorrect (red `x's). The possible transcriptions are ordered according to their word spotting score; in many instances this puts the correct transcription at the top of the list. \relax }}{51}{figure.caption.35}
\contentsline {figure}{\numberline {6.4}{\ignorespaces A histogram of spotting instances for the bigram ``nd'' divided into true and false spottings. The true spottings forms a distribution distinct from the false. \relax }}{54}{figure.caption.36}
\contentsline {figure}{\numberline {6.5}{\ignorespaces A histogram of spotting instances for the unigram ``g'' divided into true and false spottings. The true spottings are almost inline with the false distribution making them indistinguishable. \relax }}{54}{figure.caption.37}
\contentsline {figure}{\numberline {6.6}{\ignorespaces A histogram of spotting instances for the bigram ``nd'' with a curve (red) representing the data as a single distribution. The green circle shows that the estimation greatly underestimates the tail indicating there is likely a strong true instance distribution present. \relax }}{55}{figure.caption.38}
\contentsline {figure}{\numberline {6.7}{\ignorespaces The cluster spotting approval UI with a true cluster. One outlier has been identified by the user (darkened instance).\relax }}{58}{figure.caption.39}
\contentsline {figure}{\numberline {6.8}{\ignorespaces The cluster spotting approval UI with a false cluster. No outliers are present.\relax }}{59}{figure.caption.40}
\contentsline {figure}{\numberline {6.9}{\ignorespaces An example of a character probability vector for the word ``adultery''. The relative probability of each character (`a'-`z') at each horizontal position is represented both by the height and color of the graph. The discontinuities occuring at the begining and end of the word (e.g. see `x') occur due to the merging of unigram, bigram, and trigram scores.\relax }}{62}{figure.caption.41}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Part of a page of the Bentham dataset after running the CATTSS system with subword spotting approval being distributied using a two-distribution model with only bigrams. The pink boxes represent approved bigram spottings. The red text represents a transcription made by the system.\relax }}{67}{figure.caption.44}
\addvspace {10\p@ }
